{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8766f859",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d957120",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel 'tensorflow_gpu (Python 3.9.7)' was not started as it is located in an insecure location 'c:\\ProgramData\\jupyter\\kernels\\tensorflow_gpu\\kernel.json'.  \n",
      "\u001b[1;31mClick <a href='https://aka.ms/JupyterTrustedKernelPaths'>here</a> for further details, optionally update the setting <a href='command:workbench.action.openSettings?[\"jupyter.kernels.trusted\"]'>jupyter.kernels.trusted</a> to trust the kernel."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef3711",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfca0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "dataset = pd.read_csv('C:/Users/Felix Ee Jian Hui/Desktop/Degree/Sem4/FYP/Dataset/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc652b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first 5 rows\n",
    "print(\"üîπ Head of dataset:\")\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c581dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show dataset info\n",
    "print(\"\\nüîπ Dataset Information:\")\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b159f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Missing Values\n",
    "print(\"\\nüîπ Missing Values:\")\n",
    "print(dataset.isnull().sum())\n",
    "\n",
    "# Option 1: Fill missing numerical values with mean\n",
    "numeric_cols = dataset.select_dtypes(include=[np.number]).columns\n",
    "dataset[numeric_cols] = dataset[numeric_cols].fillna(dataset[numeric_cols].mean())\n",
    "\n",
    "# Option 2: Fill missing categorical values with mode\n",
    "categorical_cols = dataset.select_dtypes(include=['object']).columns\n",
    "dataset[categorical_cols] = dataset[categorical_cols].fillna(dataset[categorical_cols].mode().iloc[0])\n",
    "\n",
    "print(\"\\n‚úÖ After Filling Missing Values:\")\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6df98bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Outlier Detection and Removal (using Z-score method)\n",
    "print(\"\\nüîπ Removing Outliers:\")\n",
    "\n",
    "# ‚ùå Columns to exclude from Z-score outlier detection\n",
    "excluded_outlier_cols = ['InternetAccess', 'Extracurricular', 'PartTimeJob', \n",
    "                         'ParentSupport', 'Romantic', 'FreeTime', 'GoOut']\n",
    "\n",
    "# ‚úÖ Only apply Z-score to numerical continuous columns\n",
    "numeric_cols = dataset.select_dtypes(include=[np.number]).columns\n",
    "zscore_cols = [col for col in numeric_cols if col not in excluded_outlier_cols]\n",
    "\n",
    "# ‚úÖ Compute Z-scores and filter entries\n",
    "z_scores = np.abs(stats.zscore(dataset[zscore_cols]))\n",
    "filtered_entries = (z_scores < 3).all(axis=1)\n",
    "dataset = dataset[filtered_entries]\n",
    "\n",
    "print(\"‚úÖ Dataset shape after outlier removal:\", dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226f0208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Data Tranformation\n",
    "# Re-select numeric columns\n",
    "numeric_cols = dataset.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Exclude binary/ordinal features\n",
    "excluded_cols = ['Grade', 'SES_Quartile', 'InternetAccess', 'Extracurricular']\n",
    "continuous_cols = [col for col in numeric_cols if col not in excluded_cols]\n",
    "\n",
    "# Step 0: Save original skewness\n",
    "original_skewness = dataset[continuous_cols].skew()\n",
    "\n",
    "# Step 1: Apply Yeo-Johnson transformation\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "dataset[continuous_cols] = pt.fit_transform(dataset[continuous_cols])\n",
    "\n",
    "# Step 2: Skewness comparison\n",
    "transformed_skewness = dataset[continuous_cols].skew()\n",
    "skew_df = pd.DataFrame({\n",
    "    'Before': original_skewness,\n",
    "    'After': transformed_skewness\n",
    "})\n",
    "print(\"\\n‚úÖ Skewness Comparison (Before vs After Transformation):\")\n",
    "print(skew_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84749f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Data Standardization \n",
    "# Step 1: Identify numeric columns\n",
    "numeric_cols = dataset.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Step 2: Exclude binary or categorical numeric features from standardization\n",
    "excluded_cols = ['Grade', 'SES_Quartile', 'InternetAccess', 'Extracurricular', 'Romantic', 'PartTimeJob']\n",
    "continuous_cols = [col for col in numeric_cols if col not in excluded_cols]\n",
    "\n",
    "# Step 3: Apply StandardScaler to continuous numeric features\n",
    "scaler = StandardScaler()\n",
    "dataset[continuous_cols] = scaler.fit_transform(dataset[continuous_cols])\n",
    "\n",
    "# Step 4: Display mean and standard deviation to confirm standardization\n",
    "print(\"\\nüîπ Summary After Standardization (Mean ‚âà 0, Std ‚âà 1):\")\n",
    "print(dataset[continuous_cols].describe().loc[['mean', 'std']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc3674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Data Normalization\n",
    "# Step 1: Identify numeric columns\n",
    "numeric_cols = dataset.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Step 2: Exclude categorical/binary/ordinal numeric columns from normalization\n",
    "excluded_cols = ['Grade', 'SES_Quartile', 'InternetAccess', 'Extracurricular', 'Romantic', 'PartTimeJob']\n",
    "continuous_cols = [col for col in numeric_cols if col not in excluded_cols]\n",
    "\n",
    "# Step 3: Apply MinMaxScaler to continuous numeric features\n",
    "scaler_norm = MinMaxScaler()\n",
    "dataset[continuous_cols] = scaler_norm.fit_transform(dataset[continuous_cols])\n",
    "\n",
    "# Step 4: Preview normalized data\n",
    "print(\"\\n‚úÖ Normalized Data (First 5 Rows):\")\n",
    "print(dataset[continuous_cols].head())\n",
    "\n",
    "# Check the range after normalization\n",
    "print(\"\\nüîç Normalized Feature Ranges:\")\n",
    "print(dataset[continuous_cols].agg(['min', 'max']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6b0887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Encode Categorical Variables (if any)\n",
    "print(\"\\nüîπ Encoding Categorical Variables:\")\n",
    "\n",
    "# Identify object or category columns\n",
    "cat_cols = dataset.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(f\"üßæ Categorical columns to encode: {cat_cols}\")\n",
    "\n",
    "# Apply one-hot encoding to these columns (drop_first=True to avoid multicollinearity)\n",
    "dataset = pd.get_dummies(dataset, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Final check\n",
    "print(\"‚úÖ Final Dataset Shape after encoding:\", dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f011151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original dataset again\n",
    "original_df = pd.read_csv('C:/Users/Felix Ee Jian Hui/Desktop/Degree/Sem4/FYP/Dataset/test.csv')\n",
    "\n",
    "# Define columns to exclude from continuous data analysis\n",
    "excluded_cols = ['Grade', 'SES_Quartile', 'InternetAccess', 'Extracurricular', 'Romantic', 'PartTimeJob']\n",
    "\n",
    "# Get continuous numeric columns only\n",
    "numeric_cols = original_df.select_dtypes(include=[np.number]).columns\n",
    "continuous_cols = [col for col in numeric_cols if col not in excluded_cols]\n",
    "\n",
    "# Set plot style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Loop through each continuous column\n",
    "for col in continuous_cols:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
    "    fig.suptitle(f'Distribution of {col}: Before vs After Transformation', fontsize=16, fontweight='bold')\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Histogram ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    axes[0].hist(original_df[col].dropna(), bins=30, alpha=0.6, label='Before', color='skyblue', edgecolor='black')\n",
    "    axes[0].hist(dataset[col], bins=30, alpha=0.6, label='After', color='lightgreen', edgecolor='black')\n",
    "    axes[0].set_title(\"Histogram\")\n",
    "    axes[0].set_xlabel(col)\n",
    "    axes[0].set_ylabel(\"Frequency\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ KDE Plot ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    sns.kdeplot(original_df[col].dropna(), ax=axes[1], label='Before', color='blue', fill=True)\n",
    "    sns.kdeplot(dataset[col], ax=axes[1], label='After', color='green', fill=True)\n",
    "    axes[1].set_title(\"KDE Plot\")\n",
    "    axes[1].set_xlabel(col)\n",
    "    axes[1].legend()\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Boxplot ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    sns.boxplot(data=[original_df[col].dropna(), dataset[col]], ax=axes[2], palette=[\"skyblue\", \"lightgreen\"])\n",
    "    axes[2].set_xticklabels([\"Before\", \"After\"])\n",
    "    axes[2].set_title(\"Boxplot\")\n",
    "    axes[2].set_ylabel(col)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.85)  # Space for suptitle\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1466ee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualization\n",
    "# Load original dataset again (before transformation)\n",
    "original_df = pd.read_csv('C:/Users/Felix Ee Jian Hui/Desktop/Degree/Sem4/FYP/Dataset/test.csv')\n",
    "\n",
    "# Select continuous numeric columns (exclude ordinal/binary)\n",
    "numeric_cols = original_df.select_dtypes(include=[np.number]).columns\n",
    "excluded_cols = ['Grade', 'SES_Quartile', 'InternetAccess', 'Extracurricular', 'Romantic', 'PartTimeJob']\n",
    "continuous_cols = [col for col in numeric_cols if col not in excluded_cols]\n",
    "\n",
    "# Set up the figure\n",
    "fig, axes = plt.subplots(nrows=len(continuous_cols), ncols=2, figsize=(12, 4 * len(continuous_cols)))\n",
    "\n",
    "# Plot original vs transformed for each feature\n",
    "for idx, col in enumerate(continuous_cols):\n",
    "    # Plot original\n",
    "    axes[idx, 0].hist(original_df[col].dropna(), bins=30, alpha=0.7, edgecolor='black', color='skyblue')\n",
    "    axes[idx, 0].set_title(f'{col} - Before Transformation', fontsize=12)\n",
    "    axes[idx, 0].set_xlabel(col)\n",
    "    axes[idx, 0].set_ylabel('Frequency')\n",
    "    axes[idx, 0].grid(True)\n",
    "\n",
    "    # Plot transformed\n",
    "    axes[idx, 1].hist(dataset[col], bins=30, alpha=0.7, edgecolor='black', color='lightgreen')\n",
    "    axes[idx, 1].set_title(f'{col} - After Transformation', fontsize=12)\n",
    "    axes[idx, 1].set_xlabel(col)\n",
    "    axes[idx, 1].set_ylabel('Frequency')\n",
    "    axes[idx, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpu",
   "language": "python",
   "name": "tensorflow_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
